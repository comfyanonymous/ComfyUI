# Large Language Models

ComfyUI LTS supports text and multi-modal LLM models from the `transformers` ecosystem. This means all the LLaMA family models, LLAVA-NEXT, Phi-3, etc. are supported out-of-the-box with no configuration necessary.

![llava_example_01.gif](assets/llava_example_01.gif)

In this example, LLAVA-NEXT (LLAVA 1.6) is prompted to describe an image.

You can try the [LLAVA-NEXT](../tests/inference/workflows/llava-0.json), [Phi-3](../tests/inference/workflows/phi-4-0.json), and two [translation](../tests/inference/workflows/translation-0.json) [workflows](../tests/inference/workflows/translation-1.json).
